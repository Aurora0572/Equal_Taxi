import os
import logging
from io import BytesIO
from typing import Dict

import pandas as pd
import httpx
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi_cache import FastAPICache
from fastapi_cache.decorator import cache
from fastapi_cache.backends.inmemory import InMemoryBackend

from .constants import REQUIRED_COLS, DEFAULT_DATE, BASE_URL
from .schemas import UsageResponse, DestinationResponse, UsageSummary  # UsageSummary ì¶”ê°€

# -----------------------------------------
# í™˜ê²½ë³€ìˆ˜ & ë¡œê¹… ì„¤ì •
# -----------------------------------------
load_dotenv()
logger = logging.getLogger("taxi_api")
logging.basicConfig(level=logging.INFO)

API_KEY_USAGE = os.getenv("CALLTAXI_USAGE_KEY")
API_KEY_DEST = os.getenv("CALLTAXI_DEST_KEY")

if not API_KEY_USAGE or not API_KEY_DEST:
    logger.warning("API í‚¤ê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")

# -----------------------------------------
# FastAPI ì•±
# -----------------------------------------
app = FastAPI(
    title="ìŠ¤ë§ˆíŠ¸ ì¥ì• ì¸ ì½œíƒì‹œ ì‹œìŠ¤í…œ",
    description="ì„œìš¸ì‹œ ì¥ì• ì¸ ì½œíƒì‹œ ì‹¤ì‹œê°„ ì´ìš©í˜„í™© + ì˜ˆì¸¡/ë°°ì°¨ API",
    version="2.0",
)

# CORS ë¯¸ë“¤ì›¨ì–´ ì¶”ê°€
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.on_event("startup")
async def startup():
    FastAPICache.init(InMemoryBackend())

# -----------------------------------------
# ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸
# -----------------------------------------
@app.get("/")
async def root() -> Dict:
    return {
        "message": "ğŸš• ìŠ¤ë§ˆíŠ¸ ì¥ì• ì¸ ì½œíƒì‹œ API ì„œë²„ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.",
        "endpoints": [
            "/usage?date=YYYYMMDD",
            "/best_destinations?sDate=YYYYMMDD"
        ]
    }

# -----------------------------------------
# ë¹„ë™ê¸° HTTP ìš”ì²­ ê³µí†µ í•¨ìˆ˜
# -----------------------------------------
async def _fetch_excel_from_api(url: str) -> pd.DataFrame:
    """ì„œìš¸ì‹œ ì½œíƒì‹œ APIì—ì„œ ë°ì´í„°ë¥¼ ë¹„ë™ê¸°ë¡œ ê°€ì ¸ì˜´"""
    try:
        async with httpx.AsyncClient(timeout=15) as client:
            resp = await client.get(url)
            resp.raise_for_status()
    except httpx.RequestError as e:
        logger.error(f"API ìš”ì²­ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=502, detail="ì„œìš¸ì‹œ API ìš”ì²­ ì‹¤íŒ¨")
    except httpx.HTTPStatusError as e:
        logger.error(f"API ìƒíƒœì½”ë“œ ì˜¤ë¥˜: {e.response.status_code}")
        raise HTTPException(status_code=502, detail=f"ì„œìš¸ì‹œ API ì‘ë‹µ ì˜¤ë¥˜: {e.response.status_code}")

    content = resp.content
    head = content[:100].lower()

    # HTML í…Œì´ë¸” ì‘ë‹µ ì²˜ë¦¬
    if b"<table" in head:
        try:
            # euc-kr ì¸ì½”ë”©ìœ¼ë¡œ ë³€ê²½
            tables = pd.read_html(BytesIO(content), flavor="lxml", encoding="euc-kr")
            if not tables:
                raise ValueError("HTML ì‘ë‹µì—ì„œ í…Œì´ë¸”ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return tables[0]
        except Exception as e:
            logger.error(f"HTML í…Œì´ë¸” íŒŒì‹± ì‹¤íŒ¨: {e}")
            with open("debug_response.html", "wb") as f:
                f.write(content)
            raise HTTPException(status_code=500, detail=f"HTML íŒŒì‹± ì‹¤íŒ¨: {e}")

    # Excel íŒŒì¼ ì‘ë‹µ ì²˜ë¦¬ (openpyxl ì—”ì§„ + skiprows 1)
    try:
        df = pd.read_excel(BytesIO(content), engine="openpyxl", skiprows=1)
        return df
    except Exception as e:
        logger.error(f"ì—‘ì…€ íŒŒì‹± ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ì—‘ì…€ íŒŒì‹± ì‹¤íŒ¨: {e}")

# -----------------------------------------
# ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
# -----------------------------------------
async def fetch_daily_usage_data(date: str = "20250131") -> pd.DataFrame:
    start_date = date
    url = f"{BASE_URL}/newEXCEL0001.asp?key={API_KEY_USAGE}&sDate={start_date}&eDate={date}"
    df = await _fetch_excel_from_api(url)

    logger.info(f"Received columns: {df.columns.tolist()}")

    # ê°•ì œë¡œ ì»¬ëŸ¼ ì´ë¦„ ì§€ì • (ì—‘ì…€ êµ¬ì¡°ê°€ í•­ìƒ ê°™ë‹¤ë©´)
    expected_cols = ["ê¸°ì¤€ì¼", "ì°¨ëŸ‰ìš´í–‰", "ì ‘ìˆ˜ê±´", "íƒ‘ìŠ¹ê±´", "í‰ê· ëŒ€ê¸°ì‹œê°„", "í‰ê· ìš”ê¸ˆ", "í‰ê· ìŠ¹ì°¨ê±°ë¦¬"]
    if len(df.columns) >= len(expected_cols):
        df = df.iloc[:, :len(expected_cols)]
        df.columns = expected_cols
    
    # ìˆ«ì ì»¬ëŸ¼ ê°•ì œ ë³€í™˜
    numeric_cols = ["ì°¨ëŸ‰ìš´í–‰", "ì ‘ìˆ˜ê±´", "íƒ‘ìŠ¹ê±´", "í‰ê· ëŒ€ê¸°ì‹œê°„", "í‰ê· ìš”ê¸ˆ", "í‰ê· ìŠ¹ì°¨ê±°ë¦¬"]
    for col in numeric_cols:
        df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0)

    # Verify required columns
    missing_cols = [col for col in expected_cols if col not in df.columns]
    if missing_cols:
        logger.error(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {', '.join(missing_cols)}")
        df.to_csv("debug_columns.csv", encoding='utf-8-sig')
        raise HTTPException(
            status_code=500,
            detail=f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {', '.join(missing_cols)}. ë°›ì€ ì»¬ëŸ¼: {', '.join(df.columns)}"
        )

    return df

async def fetch_best_100_destinations(start_date: str = "20250101") -> pd.DataFrame:
    url = f"{BASE_URL}/newEXCEL0002.asp?key={API_KEY_DEST}&sDate={start_date}"
    df = await _fetch_excel_from_api(url)

    logger.info(f"Best Destinations columns: {df.columns.tolist()}")

    # ì»¬ëŸ¼ ì´ë¦„ì´ ìˆ«ìë¡œë§Œ ë“¤ì–´ì˜¤ë©´ ìˆ˜ë™ìœ¼ë¡œ ì§€ì •
    if len(df.columns) >= 5 and "cnt" not in df.columns:
        df = df.iloc[:, :5]
        df.columns = ["usedate", "oc", "og", "dong", "cnt"]

    required_cols = {"oc", "og", "dong", "cnt"}
    if not required_cols.issubset(set(df.columns)):
        raise HTTPException(status_code=500, detail="í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: oc, og, dong, cnt")

    # ì¥ì†Œëª… ì»¬ëŸ¼ ìƒì„±
    df["ì¥ì†Œëª…"] = df["oc"].astype(str) + " " + df["og"].astype(str) + " " + df["dong"].astype(str)
    df["ì´ìš©ê±´ìˆ˜"] = pd.to_numeric(df["cnt"], errors="coerce").fillna(0).astype(int)

    return df

# -----------------------------------------
# ì—”ë“œí¬ì¸íŠ¸
# -----------------------------------------
@app.get("/v2/usage", response_model=UsageResponse)
async def get_usage_stats(date: str = "20250131"):
    try:
        df = await fetch_daily_usage_data(date)

        # ì¼ìë³„ íƒ‘ìŠ¹ê±´ ìƒìœ„ 10ê°œ
        top_locations = (
            df.groupby("ê¸°ì¤€ì¼")["íƒ‘ìŠ¹ê±´"]
            .sum()
            .nlargest(10)
            .to_dict()
        )

        summary = UsageSummary(
            date=date,
            total_requests=int(df["ì ‘ìˆ˜ê±´"].sum()),
            total_rides=int(df["íƒ‘ìŠ¹ê±´"].sum()),
            total_vehicles=int(df["ì°¨ëŸ‰ìš´í–‰"].sum()),
            avg_waiting_time=float(df["í‰ê· ëŒ€ê¸°ì‹œê°„"].mean()),
            avg_fare=float(df["í‰ê· ìš”ê¸ˆ"].mean()),
            avg_distance=float(df["í‰ê· ìŠ¹ì°¨ê±°ë¦¬"].mean()),
            top_locations={str(k): int(v) for k, v in top_locations.items()}
        )

        return UsageResponse(summary=summary)

    except Exception as e:
        logger.exception("Usage stats error")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/v2/best_destinations", response_model=DestinationResponse)
@cache(expire=300)
async def get_best_destinations(sDate: str = DEFAULT_DATE[:-2] + "01"):
    try:
        df = await fetch_best_100_destinations(sDate)
        top_places = df[["ì¥ì†Œëª…", "ì´ìš©ê±´ìˆ˜"]].sort_values(by="ì´ìš©ê±´ìˆ˜", ascending=False).head(10)
        return {
            "start_date": sDate,
            "top_destinations": top_places.to_dict(orient="records")
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.exception("ë² ìŠ¤íŠ¸ ëª©ì ì§€ API ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜")
        raise HTTPException(status_code=500, detail=str(e))